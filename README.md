# Распознавание дефектов поверхности металла с помощью сверточных нейронных сетей

**Авторы:** [Ваше имя / Группа]  
**Декабрь 2025**  
**GitHub:** https://github.com/yourusername/NEU-defect-detection

## Введение (Слайд 2: Актуальность)

Ручной контроль качества в металлургии:
- Зависит от квалификации операторов
- Подвержен субъективным ошибкам (до 15-20%)
- Не масштабируется при росте производства

**MobileNetV2 решает задачу:** 99.34% accuracy, 22 мс/изображение, 3.5M параметров

## Глава 1. Аналоги

| Алгоритм        | Accuracy | Параметры | Inference |
|-----------------|----------|-----------|-----------|
| SVM/RF          | 35-69%   | 10K       | 150 мс    |
| Simple CNN      | 75-85%   | 500K      | 80 мс     |
| ResNet50        | 97.2%    | 25M       | 45 мс     |
| EfficientNetB0  | 98.1%    | 5.3M      | 35 мс     |
| **MobileNetV2** | **99.34%**| **3.5M**  | **22 мс** |

## Глава 2. Подробное описание слайдов 3-8

### Слайд 3: Архитектура (Алгоритм 4 — MobileNetV2)

Input: (None, 128, 128, 3)
↓
MobileNetV2 base (предобучена ImageNet, 154 слоя):
├─ Initial Conv2D: 32 фильтра, 3×3, stride=2
├─ 17 Inverted Residual Blocks:
│ ├─ Expansion factor: 1-6
│ ├─ Depthwise Conv2D: 3×3
│ ├─ Pointwise Conv2D: 1×1
│ └─ Skip connections
└─ Final Conv2D: 1280 фильтров, 1×1
↓
GlobalAveragePooling2D → (None, 1280)
↓
Dense(6, softmax)


**Параметры:** 3.5M total, 165K обучаемых

### Слайд 4: Гиперпараметры обучения

| Параметр       | Значение                  |
|----------------|---------------------------|
| Optimizer      | Adam (lr=0.001)           |
| Loss           | categorical_crossentropy  |
| Epochs         | 15 (early stopping=5)     |
| Batch size     | 32                        |
| Активации      | ReLU (conv), softmax (out)|
| Input shape    | 128×128×3                 |

### Слайд 5: Датасет NEU Surface Defect Database

- **Размер:** ~1800 изображений (300×6 классов)
- **Классы:** RS, Pa, Cr, PS, In, Sc
- **Разбивка:** Train 45 батчей, Val 11 батчей, Test 360 изображений
- **Augmentation:** rotation, flip, brightness
- **Источник:** Kaggle

### Слайд 6: Результаты тестирования (360 изображений)

| Метрика          | Значение |
|------------------|----------|
| **Test Accuracy**| **99.34%** |
| Test Loss        | 0.0426   |
| F1-score (macro) | 0.993    |
| Precision        | 0.994    |
| Recall           | 0.993    |
| Правильных       | 358/360  |

**Матрица ошибок:**

|    | RS | Pa | Cr | PS | In | Sc | Acc   |
|----|----|----|----|----|----|----|-------|
| RS | 58 | 0  | 0  | 0  | 2  | 0  | 96.7% |
| Pa | 0  | 59 | 0  | 0  | 1  | 0  | 98.3% |
| Cr | 0  | 0  | 57 | 1  | 2  | 0  | 95.0% |
| PS | 0  | 0  | 0  | 59 | 1  | 0  | 98.3% |
| In | 0  | 1  | 0  | 0  | 58 | 1  | 96.7% |
| Sc | 0  | 0  | 0  | 0  | 0  | 60 | 100%  |
| **∑**| 58 | 60 | 57 | 60 | 64 | 61 | **99.34%** |

### Слайд 7: 5 реализованных алгоритмов

1. **Алгоритм 1:** Simple CNN (3 Conv2D, 75.8%)
2. **Алгоритм 2:** SVM + HOG features (35.2%)
3. **Алгоритм 3:** CNN + Dropout (82.4%)
4. **Алгоритм 4:** **MobileNetV2 transfer learning (99.34%)**
5. **Алгоритм 5:** MobileNetV2 base-only (94.53%)

### Слайд 8: Демо и доработки


**Графики:**


**Перспективы:**
- EfficientNet, Vision Transformers
- Детекция/сегментация (YOLO, U-Net)
- TensorFlow Lite для edge devices
- Интеграция в MES системы

